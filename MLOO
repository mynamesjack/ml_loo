#Leave One Out classification on a one-dimensional data set. 
#I've left a 1d array just to show how it works. It should be interchangable with any one-dimenionsal data you have.
# Here we're creating three arrays. One contains our objects, one the class labels of our objects and an empty array to store the newly classified labels.
# The purpose is to see how accurate the new classifier is against the original labels.

import numpy as np

# Here we're creating three arrays. One contains our objects, one the class labels of our objects and an empty array to store the newly classified labels.
# The purpose is to see how accurate the new classifier is against the original labels.

Data = np.array([-6,-2,0,4,11,15,24])
Labels = np.array([1,2,2,1,2,1,1])
Assigned_Labels = np.empty(len(Data))


def leave_one_out(data,labels,empty):
    for i in range(len(data)):
        xn = np.delete(data,i)
        yn = np.delete(labels,i)
   #We're creating a variable without the ith object and calculating the mean of every object with a y label of 1 and another for a label of 2.
        m1 = np.mean(xn[np.where(yn==1)])
        m2 = np.mean(xn[np.where(yn==2)])
   #We calculate the threshold which is the mean of every object with label 1 + the mean of every object with label 2, divided by 2
        t = (m1+m2) / 2
    #Then we need to classified the removed object into either class 1 or class 2 and add either a 1 or 2 to the empty array, a.
        if (m1 - m2) * (t-data[i]) > 0:
            empty[i] = 2
        else:
            empty[i] = 1
#Here we can print the array of class labels and compare them to the original array, y, to see how they compare and calculate an error rate.
    error = 0
    for i in range(len(labels)):
        if empty[i] != labels[i]:
            error +=1
    l_error = error / len(labels)
    print(f"The Leave One Out Error is {l_error} ")

leave_one_out(Data,Labels,Assigned_Labels)
